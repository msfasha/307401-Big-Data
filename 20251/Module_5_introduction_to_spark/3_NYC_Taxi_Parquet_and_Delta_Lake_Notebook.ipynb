{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9944bbcf",
   "metadata": {},
   "source": [
    "# NYC Taxi Analytics with PySpark, Parquet, and Delta Lake\n",
    "\n",
    "This notebook provides a comprehensive introduction to working with the NYC Taxi dataset using PySpark, Parquet, and Delta Lake. The material is intentionally verbose and explanatory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10a5c89",
   "metadata": {},
   "source": [
    "## 1. Why Parquet Matters\n",
    "\n",
    "Parquet is a columnar storage format optimized for analytical workloads. It reduces I/O, improves compression, and enables efficient query execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5ff9e3",
   "metadata": {},
   "source": [
    "## 2. Spark Session Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d5f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder     .appName(\"NYC Taxi Parquet and Delta Lake\")     .getOrCreate()\n",
    "\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd4b135",
   "metadata": {},
   "source": [
    "## 3. Loading the NYC Taxi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275bb5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = spark.read.parquet(\"/content/nyc_taxi_parquet/\")\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb37e7d5",
   "metadata": {},
   "source": [
    "## 4. Column Pruning in Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b91a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.select(\"pickup_datetime\", \"fare_amount\")   .filter(\"fare_amount > 50\")   .explain(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693c67c2",
   "metadata": {},
   "source": [
    "## 5. Partitioning the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd70c903",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import year, month\n",
    "\n",
    "df_part = df.withColumn(\"pickup_year\", year(\"pickup_datetime\"))             .withColumn(\"pickup_month\", month(\"pickup_datetime\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f61e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_part.write     .mode(\"overwrite\")     .partitionBy(\"pickup_year\", \"pickup_month\")     .parquet(\"/content/nyc_taxi_partitioned/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cae1e1",
   "metadata": {},
   "source": [
    "## 6. Delta Lake Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd70aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install delta-spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5638bb20",
   "metadata": {},
   "source": [
    "## 7. Enable Delta Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6716fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder     .appName(\"NYC Taxi Delta Lake\")     .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")     .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")     .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e25670f",
   "metadata": {},
   "source": [
    "## 8. Writing Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43503c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_part.write     .format(\"delta\")     .mode(\"overwrite\")     .partitionBy(\"pickup_year\", \"pickup_month\")     .save(\"/content/nyc_taxi_delta/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e025cb5",
   "metadata": {},
   "source": [
    "## 9. Reading Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78160bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_delta = spark.read.format(\"delta\").load(\"/content/nyc_taxi_delta/\")\n",
    "df_delta.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a774ad58",
   "metadata": {},
   "source": [
    "## 10. Time Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f1f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_delta.history().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77d3a9e",
   "metadata": {},
   "source": [
    "## 11. Updates and Deletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f2872",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "delta_table = DeltaTable.forPath(spark, \"/content/nyc_taxi_delta/\")\n",
    "delta_table.delete(\"trip_distance < 0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec0d7b7",
   "metadata": {},
   "source": [
    "## Final Summary\n",
    "\n",
    "Parquet provides efficient storage, while Delta Lake adds reliability, transactions, and production-grade data management."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
